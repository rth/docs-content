---
meta:
  title: Mixtral-8x7B-Instruct-v0.1 model
  description: This page explains the Mixtral-8x7B-Instruct-v0.1 model
content:
  h1:  Mixtral-8x7B-Instruct-v0.1 model
  paragraph: This page explains the Mixtral-8x7B-Instruct-v0.1 model
tags: 
categories:
  - ia
---

## Model overview

| Attribute       | Details                            |
|-----------------|------------------------------------|
| Provider        | [Mistral](https://mistral.ai/technology/#models)                         |
| Model Name      | `mixtral-8x7B-Instruct-v0.1`       |
| Compatible Instances | H100-2 (FP16)                 |

## Model name

```bash
mixtral-8x7B-Instruct-v0.1
```

## Compatible Instances

- [H100-2 (FP16)](https://www.scaleway.com/en/h100-pcie-try-it-now/)

## Model introduction

Mixtral-8x7B-Instruct-v0.1, developed by Mistral, is tailored for instructional platforms and virtual assistants.
Trained on vast instructional datasets, it provides clear and concise instructions across various domains, enhancing user learning experiences.

## Why you will love it

Mixtral-8x7B-Instruct-v0.1 prioritizes user privacy and data sovereignty. Additionally, it was trained on the [Nabuchodonosor supercomputer](https://www.scaleway.com/en/ai-supercomputers/), ensuring high-quality instruction generation and performance.
Whether you are developing virtual assistants or educational platforms, Mixtral-8x7B-Instruct-v0.1 offers reliability and excellence.

## How to use it 
